{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IM939 Lab 2 - Part 1\n",
    "\n",
    "Last session we loaded data using [Pandas](https://pandas.pydata.org/). Here we explore how to use Pandas to read in, process and explore data.\n",
    "\n",
    "As before we load pandas and use the read_csv method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/raw/office_ratings.csv', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188 entries, 0 to 187\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   season       188 non-null    int64  \n",
      " 1   episode      188 non-null    int64  \n",
      " 2   title        188 non-null    object \n",
      " 3   imdb_rating  188 non-null    float64\n",
      " 4   total_votes  188 non-null    int64  \n",
      " 5   air_date     188 non-null    object \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 8.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help!\n",
    "\n",
    "Python has inbuilt documentation. To access this add a ? before an object or method.\n",
    "\n",
    "For example, our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'WriteBuffer[str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_cols\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmemory_usage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshow_counts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'None'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Print a concise summary of a DataFrame.\n",
      "\n",
      "This method prints information about a DataFrame including\n",
      "the index dtype and columns, non-null values and memory usage.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "verbose : bool, optional\n",
      "    Whether to print the full summary. By default, the setting in\n",
      "    ``pandas.options.display.max_info_columns`` is followed.\n",
      "buf : writable buffer, defaults to sys.stdout\n",
      "    Where to send the output. By default, the output is printed to\n",
      "    sys.stdout. Pass a writable buffer if you need to further process\n",
      "    the output.\n",
      "max_cols : int, optional\n",
      "    When to switch from the verbose to the truncated output. If the\n",
      "    DataFrame has more than `max_cols` columns, the truncated output\n",
      "    is used. By default, the setting in\n",
      "    ``pandas.options.display.max_info_columns`` is used.\n",
      "memory_usage : bool, str, optional\n",
      "    Specifies whether total memory usage of the DataFrame\n",
      "    elements (including the index) should be displayed. By default,\n",
      "    this follows the ``pandas.options.display.memory_usage`` setting.\n",
      "\n",
      "    True always show memory usage. False never shows memory usage.\n",
      "    A value of 'deep' is equivalent to \"True with deep introspection\".\n",
      "    Memory usage is shown in human-readable units (base-2\n",
      "    representation). Without deep introspection a memory estimation is\n",
      "    made based in column dtype and number of rows assuming values\n",
      "    consume the same memory amount for corresponding dtypes. With deep\n",
      "    memory introspection, a real memory usage calculation is performed\n",
      "    at the cost of computational resources. See the\n",
      "    :ref:`Frequently Asked Questions <df-memory-usage>` for more\n",
      "    details.\n",
      "show_counts : bool, optional\n",
      "    Whether to show the non-null counts. By default, this is shown\n",
      "    only if the DataFrame is smaller than\n",
      "    ``pandas.options.display.max_info_rows`` and\n",
      "    ``pandas.options.display.max_info_columns``. A value of True always\n",
      "    shows the counts, and False never shows the counts.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "None\n",
      "    This method prints a summary of a DataFrame and returns None.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.describe: Generate descriptive statistics of DataFrame\n",
      "    columns.\n",
      "DataFrame.memory_usage: Memory usage of DataFrame columns.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> int_values = [1, 2, 3, 4, 5]\n",
      ">>> text_values = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']\n",
      ">>> float_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      ">>> df = pd.DataFrame({\"int_col\": int_values, \"text_col\": text_values,\n",
      "...                   \"float_col\": float_values})\n",
      ">>> df\n",
      "    int_col text_col  float_col\n",
      "0        1    alpha       0.00\n",
      "1        2     beta       0.25\n",
      "2        3    gamma       0.50\n",
      "3        4    delta       0.75\n",
      "4        5  epsilon       1.00\n",
      "\n",
      "Prints information of all columns:\n",
      "\n",
      ">>> df.info(verbose=True)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   int_col    5 non-null      int64\n",
      " 1   text_col   5 non-null      object\n",
      " 2   float_col  5 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 248.0+ bytes\n",
      "\n",
      "Prints a summary of columns count and its dtypes but not per column\n",
      "information:\n",
      "\n",
      ">>> df.info(verbose=False)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Columns: 3 entries, int_col to float_col\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 248.0+ bytes\n",
      "\n",
      "Pipe output of DataFrame.info to buffer instead of sys.stdout, get\n",
      "buffer content and writes to a text file:\n",
      "\n",
      ">>> import io\n",
      ">>> buffer = io.StringIO()\n",
      ">>> df.info(buf=buffer)\n",
      ">>> s = buffer.getvalue()\n",
      ">>> with open(\"df_info.txt\", \"w\",\n",
      "...           encoding=\"utf-8\") as f:  # doctest: +SKIP\n",
      "...     f.write(s)\n",
      "260\n",
      "\n",
      "The `memory_usage` parameter allows deep introspection mode, specially\n",
      "useful for big DataFrames and fine-tune memory optimization:\n",
      "\n",
      ">>> random_strings_array = np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      ">>> df = pd.DataFrame({\n",
      "...     'column_1': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      "...     'column_2': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      "...     'column_3': np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      "... })\n",
      ">>> df.info()\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count    Dtype\n",
      "---  ------    --------------    -----\n",
      " 0   column_1  1000000 non-null  object\n",
      " 1   column_2  1000000 non-null  object\n",
      " 2   column_3  1000000 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 22.9+ MB\n",
      "\n",
      ">>> df.info(memory_usage='deep')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count    Dtype\n",
      "---  ------    --------------    -----\n",
      " 0   column_1  1000000 non-null  object\n",
      " 1   column_2  1000000 non-null  object\n",
      " 2   column_3  1000000 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 165.9 MB\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/IM939/lib/python3.11/site-packages/pandas/core/frame.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "?df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dtypes property (properties of obejct are values associated with the object and are not called with a () at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        property\n",
      "\u001b[0;31mString form:\u001b[0m <property object at 0x110093ce0>\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "Return the dtypes in the DataFrame.\n",
      "\n",
      "This returns a Series with the data type of each column.\n",
      "The result's index is the original DataFrame's columns. Columns\n",
      "with mixed types are stored with the ``object`` dtype. See\n",
      ":ref:`the User Guide <basics.dtypes>` for more.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "pandas.Series\n",
      "    The data type of each column.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> df = pd.DataFrame({'float': [1.0],\n",
      "...                    'int': [1],\n",
      "...                    'datetime': [pd.Timestamp('20180310')],\n",
      "...                    'string': ['foo']})\n",
      ">>> df.dtypes\n",
      "float              float64\n",
      "int                  int64\n",
      "datetime    datetime64[ns]\n",
      "string              object\n",
      "dtype: object"
     ]
    }
   ],
   "source": [
    "?df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The info method for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'WriteBuffer[str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_cols\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmemory_usage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshow_counts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'None'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Print a concise summary of a DataFrame.\n",
      "\n",
      "This method prints information about a DataFrame including\n",
      "the index dtype and columns, non-null values and memory usage.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "verbose : bool, optional\n",
      "    Whether to print the full summary. By default, the setting in\n",
      "    ``pandas.options.display.max_info_columns`` is followed.\n",
      "buf : writable buffer, defaults to sys.stdout\n",
      "    Where to send the output. By default, the output is printed to\n",
      "    sys.stdout. Pass a writable buffer if you need to further process\n",
      "    the output.\n",
      "max_cols : int, optional\n",
      "    When to switch from the verbose to the truncated output. If the\n",
      "    DataFrame has more than `max_cols` columns, the truncated output\n",
      "    is used. By default, the setting in\n",
      "    ``pandas.options.display.max_info_columns`` is used.\n",
      "memory_usage : bool, str, optional\n",
      "    Specifies whether total memory usage of the DataFrame\n",
      "    elements (including the index) should be displayed. By default,\n",
      "    this follows the ``pandas.options.display.memory_usage`` setting.\n",
      "\n",
      "    True always show memory usage. False never shows memory usage.\n",
      "    A value of 'deep' is equivalent to \"True with deep introspection\".\n",
      "    Memory usage is shown in human-readable units (base-2\n",
      "    representation). Without deep introspection a memory estimation is\n",
      "    made based in column dtype and number of rows assuming values\n",
      "    consume the same memory amount for corresponding dtypes. With deep\n",
      "    memory introspection, a real memory usage calculation is performed\n",
      "    at the cost of computational resources. See the\n",
      "    :ref:`Frequently Asked Questions <df-memory-usage>` for more\n",
      "    details.\n",
      "show_counts : bool, optional\n",
      "    Whether to show the non-null counts. By default, this is shown\n",
      "    only if the DataFrame is smaller than\n",
      "    ``pandas.options.display.max_info_rows`` and\n",
      "    ``pandas.options.display.max_info_columns``. A value of True always\n",
      "    shows the counts, and False never shows the counts.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "None\n",
      "    This method prints a summary of a DataFrame and returns None.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.describe: Generate descriptive statistics of DataFrame\n",
      "    columns.\n",
      "DataFrame.memory_usage: Memory usage of DataFrame columns.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> int_values = [1, 2, 3, 4, 5]\n",
      ">>> text_values = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']\n",
      ">>> float_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      ">>> df = pd.DataFrame({\"int_col\": int_values, \"text_col\": text_values,\n",
      "...                   \"float_col\": float_values})\n",
      ">>> df\n",
      "    int_col text_col  float_col\n",
      "0        1    alpha       0.00\n",
      "1        2     beta       0.25\n",
      "2        3    gamma       0.50\n",
      "3        4    delta       0.75\n",
      "4        5  epsilon       1.00\n",
      "\n",
      "Prints information of all columns:\n",
      "\n",
      ">>> df.info(verbose=True)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   int_col    5 non-null      int64\n",
      " 1   text_col   5 non-null      object\n",
      " 2   float_col  5 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 248.0+ bytes\n",
      "\n",
      "Prints a summary of columns count and its dtypes but not per column\n",
      "information:\n",
      "\n",
      ">>> df.info(verbose=False)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Columns: 3 entries, int_col to float_col\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 248.0+ bytes\n",
      "\n",
      "Pipe output of DataFrame.info to buffer instead of sys.stdout, get\n",
      "buffer content and writes to a text file:\n",
      "\n",
      ">>> import io\n",
      ">>> buffer = io.StringIO()\n",
      ">>> df.info(buf=buffer)\n",
      ">>> s = buffer.getvalue()\n",
      ">>> with open(\"df_info.txt\", \"w\",\n",
      "...           encoding=\"utf-8\") as f:  # doctest: +SKIP\n",
      "...     f.write(s)\n",
      "260\n",
      "\n",
      "The `memory_usage` parameter allows deep introspection mode, specially\n",
      "useful for big DataFrames and fine-tune memory optimization:\n",
      "\n",
      ">>> random_strings_array = np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      ">>> df = pd.DataFrame({\n",
      "...     'column_1': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      "...     'column_2': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      "...     'column_3': np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      "... })\n",
      ">>> df.info()\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count    Dtype\n",
      "---  ------    --------------    -----\n",
      " 0   column_1  1000000 non-null  object\n",
      " 1   column_2  1000000 non-null  object\n",
      " 2   column_3  1000000 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 22.9+ MB\n",
      "\n",
      ">>> df.info(memory_usage='deep')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count    Dtype\n",
      "---  ------    --------------    -----\n",
      " 0   column_1  1000000 non-null  object\n",
      " 1   column_2  1000000 non-null  object\n",
      " 2   column_3  1000000 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 165.9 MB\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/IM939/lib/python3.11/site-packages/pandas/core/frame.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "?df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is quite long. But goes give you the various arguments (options) you can use with the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdelimiter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mheader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"int | Sequence[int] | None | Literal['infer']\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Sequence[Hashable] | None | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mindex_col\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'IndexLabel | Literal[False] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'DtypeArg | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'CSVEngine | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrue_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfalse_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mskipinitialspace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mskipfooter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnrows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mna_filter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mskip_blank_lines\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mparse_dates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | Sequence[Hashable] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkeep_date_col\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdate_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdate_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdayfirst\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcache_dates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'CompressionOptions'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mthousands\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdecimal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlineterminator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mquoting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdoublequote\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mescapechar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcomment\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoding_errors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'strict'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdialect\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | csv.Dialect | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mon_bad_lines\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmemory_map\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfloat_precision\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Literal['high', 'legacy'] | None\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'StorageOptions'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtype_backend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'DtypeBackend | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'DataFrame | TextFileReader'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Read a comma-separated values (csv) file into DataFrame.\n",
      "\n",
      "Also supports optionally iterating or breaking of the file\n",
      "into chunks.\n",
      "\n",
      "Additional help can be found in the online docs for\n",
      "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "filepath_or_buffer : str, path object or file-like object\n",
      "    Any valid string path is acceptable. The string could be a URL. Valid\n",
      "    URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "\n",
      "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "\n",
      "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "    a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "sep : str, default ','\n",
      "    Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
      "    the separator, but the Python parsing engine can, meaning the latter will\n",
      "    be used and automatically detect the separator by Python's builtin sniffer\n",
      "    tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
      "    different from ``'\\s+'`` will be interpreted as regular expressions and\n",
      "    will also force the use of the Python parsing engine. Note that regex\n",
      "    delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "delimiter : str, default ``None``\n",
      "    Alias for sep.\n",
      "header : int, list of int, None, default 'infer'\n",
      "    Row number(s) to use as the column names, and the start of the\n",
      "    data.  Default behavior is to infer the column names: if no names\n",
      "    are passed the behavior is identical to ``header=0`` and column\n",
      "    names are inferred from the first line of the file, if column\n",
      "    names are passed explicitly then the behavior is identical to\n",
      "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "    replace existing names. The header can be a list of integers that\n",
      "    specify row locations for a multi-index on the columns\n",
      "    e.g. [0,1,3]. Intervening rows that are not specified will be\n",
      "    skipped (e.g. 2 in this example is skipped). Note that this\n",
      "    parameter ignores commented lines and empty lines if\n",
      "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "    data rather than the first line of the file.\n",
      "names : array-like, optional\n",
      "    List of column names to use. If the file contains a header row,\n",
      "    then you should explicitly pass ``header=0`` to override the column names.\n",
      "    Duplicates in this list are not allowed.\n",
      "index_col : int, str, sequence of int / str, or False, optional, default ``None``\n",
      "  Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
      "  string name or column index. If a sequence of int / str is given, a\n",
      "  MultiIndex is used.\n",
      "\n",
      "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "  column as the index, e.g. when you have a malformed file with delimiters at\n",
      "  the end of each line.\n",
      "usecols : list-like or callable, optional\n",
      "    Return a subset of the columns. If list-like, all elements must either\n",
      "    be positional (i.e. integer indices into the document columns) or strings\n",
      "    that correspond to column names provided either by the user in `names` or\n",
      "    inferred from the document header row(s). If ``names`` are given, the document\n",
      "    header row(s) are not taken into account. For example, a valid list-like\n",
      "    `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "    To instantiate a DataFrame from ``data`` with element order preserved use\n",
      "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
      "    in ``['foo', 'bar']`` order or\n",
      "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "    for ``['bar', 'foo']`` order.\n",
      "\n",
      "    If callable, the callable function will be evaluated against the column\n",
      "    names, returning names where the callable function evaluates to True. An\n",
      "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "    parsing time and lower memory usage.\n",
      "dtype : Type name or dict of column -> type, optional\n",
      "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
      "    'c': 'Int64'}\n",
      "    Use `str` or `object` together with suitable `na_values` settings\n",
      "    to preserve and not interpret dtype.\n",
      "    If converters are specified, they will be applied INSTEAD\n",
      "    of dtype conversion.\n",
      "\n",
      "    .. versionadded:: 1.5.0\n",
      "\n",
      "        Support for defaultdict was added. Specify a defaultdict as input where\n",
      "        the default determines the dtype of the columns which are not explicitly\n",
      "        listed.\n",
      "engine : {'c', 'python', 'pyarrow'}, optional\n",
      "    Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
      "    is currently more feature-complete. Multithreading is currently only supported by\n",
      "    the pyarrow engine.\n",
      "\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "        The \"pyarrow\" engine was added as an *experimental* engine, and some features\n",
      "        are unsupported, or may not work correctly, with this engine.\n",
      "converters : dict, optional\n",
      "    Dict of functions for converting values in certain columns. Keys can either\n",
      "    be integers or column labels.\n",
      "true_values : list, optional\n",
      "    Values to consider as True in addition to case-insensitive variants of \"True\".\n",
      "false_values : list, optional\n",
      "    Values to consider as False in addition to case-insensitive variants of \"False\".\n",
      "skipinitialspace : bool, default False\n",
      "    Skip spaces after delimiter.\n",
      "skiprows : list-like, int or callable, optional\n",
      "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "    at the start of the file.\n",
      "\n",
      "    If callable, the callable function will be evaluated against the row\n",
      "    indices, returning True if the row should be skipped and False otherwise.\n",
      "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "skipfooter : int, default 0\n",
      "    Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
      "nrows : int, optional\n",
      "    Number of rows of file to read. Useful for reading pieces of large files.\n",
      "na_values : scalar, str, list-like, or dict, optional\n",
      "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "    per-column NA values.  By default the following values are interpreted as\n",
      "    NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "    '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'None',\n",
      "    'n/a', 'nan', 'null'.\n",
      "keep_default_na : bool, default True\n",
      "    Whether or not to include the default NaN values when parsing the data.\n",
      "    Depending on whether `na_values` is passed in, the behavior is as follows:\n",
      "\n",
      "    * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
      "      is appended to the default NaN values used for parsing.\n",
      "    * If `keep_default_na` is True, and `na_values` are not specified, only\n",
      "      the default NaN values are used for parsing.\n",
      "    * If `keep_default_na` is False, and `na_values` are specified, only\n",
      "      the NaN values specified `na_values` are used for parsing.\n",
      "    * If `keep_default_na` is False, and `na_values` are not specified, no\n",
      "      strings will be parsed as NaN.\n",
      "\n",
      "    Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
      "    `na_values` parameters will be ignored.\n",
      "na_filter : bool, default True\n",
      "    Detect missing value markers (empty strings and the value of na_values). In\n",
      "    data without any NAs, passing na_filter=False can improve the performance\n",
      "    of reading a large file.\n",
      "verbose : bool, default False\n",
      "    Indicate number of NA values placed in non-numeric columns.\n",
      "skip_blank_lines : bool, default True\n",
      "    If True, skip over blank lines rather than interpreting as NaN values.\n",
      "parse_dates : bool or list of int or names or list of lists or dict, default False\n",
      "    The behavior is as follows:\n",
      "\n",
      "    * boolean. If True -> try parsing the index.\n",
      "    * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "      each as a separate date column.\n",
      "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "      a single date column.\n",
      "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
      "      result 'foo'\n",
      "\n",
      "    If a column or index cannot be represented as an array of datetimes,\n",
      "    say because of an unparsable value or a mixture of timezones, the column\n",
      "    or index will be returned unaltered as an object data type. For\n",
      "    non-standard datetime parsing, use ``pd.to_datetime`` after\n",
      "    ``pd.read_csv``.\n",
      "\n",
      "    Note: A fast-path exists for iso8601-formatted dates.\n",
      "infer_datetime_format : bool, default False\n",
      "    If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
      "    format of the datetime strings in the columns, and if it can be inferred,\n",
      "    switch to a faster method of parsing them. In some cases this can increase\n",
      "    the parsing speed by 5-10x.\n",
      "\n",
      "    .. deprecated:: 2.0.0\n",
      "        A strict version of this argument is now the default, passing it has no effect.\n",
      "\n",
      "keep_date_col : bool, default False\n",
      "    If True and `parse_dates` specifies combining multiple columns then\n",
      "    keep the original columns.\n",
      "date_parser : function, optional\n",
      "    Function to use for converting a sequence of string columns to an array of\n",
      "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "    string values from the columns defined by `parse_dates` into a single array\n",
      "    and pass that; and 3) call `date_parser` once for each row using one or\n",
      "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "    arguments.\n",
      "\n",
      "    .. deprecated:: 2.0.0\n",
      "       Use ``date_format`` instead, or read in as ``object`` and then apply\n",
      "       :func:`to_datetime` as-needed.\n",
      "date_format : str or dict of column -> format, default ``None``\n",
      "   If used in conjunction with ``parse_dates``, will parse dates according to this\n",
      "   format. For anything more complex,\n",
      "   please read in as ``object`` and then apply :func:`to_datetime` as-needed.\n",
      "\n",
      "   .. versionadded:: 2.0.0\n",
      "dayfirst : bool, default False\n",
      "    DD/MM format dates, international and European format.\n",
      "cache_dates : bool, default True\n",
      "    If True, use a cache of unique, converted dates to apply the datetime\n",
      "    conversion. May produce significant speed-up when parsing duplicate\n",
      "    date strings, especially ones with timezone offsets.\n",
      "\n",
      "iterator : bool, default False\n",
      "    Return TextFileReader object for iteration or getting chunks with\n",
      "    ``get_chunk()``.\n",
      "\n",
      "    .. versionchanged:: 1.2\n",
      "\n",
      "       ``TextFileReader`` is a context manager.\n",
      "chunksize : int, optional\n",
      "    Return TextFileReader object for iteration.\n",
      "    See the `IO Tools docs\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "    for more information on ``iterator`` and ``chunksize``.\n",
      "\n",
      "    .. versionchanged:: 1.2\n",
      "\n",
      "       ``TextFileReader`` is a context manager.\n",
      "compression : str or dict, default 'infer'\n",
      "    For on-the-fly decompression of on-disk data. If 'infer' and 'filepath_or_buffer' is\n",
      "    path-like, then detect compression from the following extensions: '.gz',\n",
      "    '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "    (otherwise no compression).\n",
      "    If using 'zip' or 'tar', the ZIP file must contain only one data file to be read in.\n",
      "    Set to ``None`` for no decompression.\n",
      "    Can also be a dict with key ``'method'`` set\n",
      "    to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      "    key-value pairs are forwarded to\n",
      "    ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "    ``bz2.BZ2File``, ``zstandard.ZstdDecompressor`` or\n",
      "    ``tarfile.TarFile``, respectively.\n",
      "    As an example, the following could be passed for Zstandard decompression using a\n",
      "    custom compression dictionary:\n",
      "    ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
      "\n",
      "    .. versionadded:: 1.5.0\n",
      "        Added support for `.tar` files.\n",
      "\n",
      "    .. versionchanged:: 1.4.0 Zstandard support.\n",
      "\n",
      "thousands : str, optional\n",
      "    Thousands separator.\n",
      "decimal : str, default '.'\n",
      "    Character to recognize as decimal point (e.g. use ',' for European data).\n",
      "lineterminator : str (length 1), optional\n",
      "    Character to break file into lines. Only valid with C parser.\n",
      "quotechar : str (length 1), optional\n",
      "    The character used to denote the start and end of a quoted item. Quoted\n",
      "    items can include the delimiter and it will be ignored.\n",
      "quoting : int or csv.QUOTE_* instance, default 0\n",
      "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "doublequote : bool, default ``True``\n",
      "   When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
      "   whether or not to interpret two consecutive quotechar elements INSIDE a\n",
      "   field as a single ``quotechar`` element.\n",
      "escapechar : str (length 1), optional\n",
      "    One-character string used to escape other characters.\n",
      "comment : str, optional\n",
      "    Indicates remainder of line should not be parsed. If found at the beginning\n",
      "    of a line, the line will be ignored altogether. This parameter must be a\n",
      "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "    fully commented lines are ignored by the parameter `header` but not by\n",
      "    `skiprows`. For example, if ``comment='#'``, parsing\n",
      "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
      "    treated as the header.\n",
      "encoding : str, optional, default \"utf-8\"\n",
      "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "    standard encodings\n",
      "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "\n",
      "    .. versionchanged:: 1.2\n",
      "\n",
      "       When ``encoding`` is ``None``, ``errors=\"replace\"`` is passed to\n",
      "       ``open()``. Otherwise, ``errors=\"strict\"`` is passed to ``open()``.\n",
      "       This behavior was previously only the case for ``engine=\"python\"``.\n",
      "\n",
      "    .. versionchanged:: 1.3.0\n",
      "\n",
      "       ``encoding_errors`` is a new argument. ``encoding`` has no longer an\n",
      "       influence on how encoding errors are handled.\n",
      "\n",
      "encoding_errors : str, optional, default \"strict\"\n",
      "    How encoding errors are treated. `List of possible values\n",
      "    <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "\n",
      "    .. versionadded:: 1.3.0\n",
      "\n",
      "dialect : str or csv.Dialect, optional\n",
      "    If provided, this parameter will override values (default or not) for the\n",
      "    following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
      "    `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
      "    override values, a ParserWarning will be issued. See csv.Dialect\n",
      "    documentation for more details.\n",
      "on_bad_lines : {'error', 'warn', 'skip'} or callable, default 'error'\n",
      "    Specifies what to do upon encountering a bad line (a line with too many fields).\n",
      "    Allowed values are :\n",
      "\n",
      "        - 'error', raise an Exception when a bad line is encountered.\n",
      "        - 'warn', raise a warning when a bad line is encountered and skip that line.\n",
      "        - 'skip', skip bad lines without raising or warning when they are encountered.\n",
      "\n",
      "    .. versionadded:: 1.3.0\n",
      "\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "        - callable, function with signature\n",
      "          ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
      "          bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
      "          If the function returns ``None``, the bad line will be ignored.\n",
      "          If the function returns a new list of strings with more elements than\n",
      "          expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
      "          Only supported when ``engine=\"python\"``\n",
      "\n",
      "delim_whitespace : bool, default False\n",
      "    Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
      "    used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "    is set to True, nothing should be passed in for the ``delimiter``\n",
      "    parameter.\n",
      "low_memory : bool, default True\n",
      "    Internally process the file in chunks, resulting in lower memory use\n",
      "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "    types either set False, or specify the type with the `dtype` parameter.\n",
      "    Note that the entire file is read into a single DataFrame regardless,\n",
      "    use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
      "    (Only valid with C parser).\n",
      "memory_map : bool, default False\n",
      "    If a filepath is provided for `filepath_or_buffer`, map the file object\n",
      "    directly onto memory and access the data directly from there. Using this\n",
      "    option can improve performance because there is no longer any I/O overhead.\n",
      "float_precision : str, optional\n",
      "    Specifies which converter the C engine should use for floating-point\n",
      "    values. The options are ``None`` or 'high' for the ordinary converter,\n",
      "    'legacy' for the original lower precision pandas converter, and\n",
      "    'round_trip' for the round-trip converter.\n",
      "\n",
      "    .. versionchanged:: 1.2\n",
      "\n",
      "storage_options : dict, optional\n",
      "    Extra options that make sense for a particular storage connection, e.g.\n",
      "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "    are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "    URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "    forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "    details, and for more examples on storage options refer `here\n",
      "    <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "    highlight=storage_options#reading-writing-remote-files>`_.\n",
      "\n",
      "    .. versionadded:: 1.2\n",
      "\n",
      "dtype_backend : {\"numpy_nullable\", \"pyarrow\"}, defaults to NumPy backed DataFrames\n",
      "    Which dtype_backend to use, e.g. whether a DataFrame should have NumPy\n",
      "    arrays, nullable dtypes are used for all dtypes that have a nullable\n",
      "    implementation when \"numpy_nullable\" is set, pyarrow is used for all\n",
      "    dtypes if \"pyarrow\" is set.\n",
      "\n",
      "    The dtype_backends are still experimential.\n",
      "\n",
      "    .. versionadded:: 2.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "DataFrame or TextFileReader\n",
      "    A comma-separated values (csv) file is returned as two-dimensional\n",
      "    data structure with labeled axes.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/IM939/lib/python3.11/site-packages/pandas/io/parsers/readers.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "?pd.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas documentation is rather good. Relevent to our below work is:\n",
    "\n",
    "* [What kind of data does pandas handle?](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/01_table_oriented.html#min-tut-01-tableoriented)\n",
    "* [How to calculate summary statistics?](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/01_table_oriented.html#min-tut-01-tableoriented)\n",
    "* [How to create plots in pandas?](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/04_plotting.html#min-tut-04-plotting)\n",
    "* [How to handle time series data with ease?](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/09_timeseries.html#min-tut-09-timeseries)\n",
    "\n",
    "I also found [a rather nice series of lessons a kind person put together](https://bitbucket.org/hrojas/learn-pandas/src/master/). There are lots of online tutorials which will help you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we find out the structure of our data?\n",
    "\n",
    "Well, the variable df is now a pandas DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame object has lots of built in methods and attributes.\n",
    "\n",
    "The info method gives us information about datatypes, dimensions and the presence of null values in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188 entries, 0 to 187\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   season       188 non-null    int64  \n",
      " 1   episode      188 non-null    int64  \n",
      " 2   title        188 non-null    object \n",
      " 3   imdb_rating  188 non-null    float64\n",
      " 4   total_votes  188 non-null    int64  \n",
      " 5   air_date     188 non-null    object \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 8.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can just look at the datatypes if we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season           int64\n",
       "episode          int64\n",
       "title           object\n",
       "imdb_rating    float64\n",
       "total_votes      int64\n",
       "air_date        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or just the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there are only 188 rows. But for larger datasets we might want to look at the head (top 5) and tail (bottom 5) rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>title</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>air_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3706</td>\n",
       "      <td>2005-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Diversity Day</td>\n",
       "      <td>8.3</td>\n",
       "      <td>3566</td>\n",
       "      <td>2005-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2983</td>\n",
       "      <td>2005-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The Alliance</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2886</td>\n",
       "      <td>2005-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3179</td>\n",
       "      <td>2005-04-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  episode          title  imdb_rating  total_votes    air_date\n",
       "0       1        1          Pilot          7.6         3706  2005-03-24\n",
       "1       1        2  Diversity Day          8.3         3566  2005-03-29\n",
       "2       1        3    Health Care          7.9         2983  2005-04-05\n",
       "3       1        4   The Alliance          8.1         2886  2005-04-12\n",
       "4       1        5     Basketball          8.4         3179  2005-04-19"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>title</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>air_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>Stairmageddon</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1484</td>\n",
       "      <td>2013-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>Paper Airplane</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1482</td>\n",
       "      <td>2013-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>Livin' the Dream</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2041</td>\n",
       "      <td>2013-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>A.A.R.M.</td>\n",
       "      <td>9.3</td>\n",
       "      <td>2860</td>\n",
       "      <td>2013-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>Finale</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7934</td>\n",
       "      <td>2013-05-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season  episode             title  imdb_rating  total_votes    air_date\n",
       "183       9       19     Stairmageddon          8.0         1484  2013-04-11\n",
       "184       9       20    Paper Airplane          8.0         1482  2013-04-25\n",
       "185       9       21  Livin' the Dream          8.9         2041  2013-05-02\n",
       "186       9       22          A.A.R.M.          9.3         2860  2013-05-09\n",
       "187       9       23            Finale          9.7         7934  2013-05-16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may need to put together a dataset.\n",
    "\n",
    "Consider the two dataframe below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('data/raw/office1.csv', encoding='UTF-8')\n",
    "df_2 = pd.read_csv('data/raw/office2.csv', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>imdb_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5-1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9-13</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5-6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-23</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9-16</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  season  episode  imdb_rating\n",
       "0   5-1       5        1          8.8\n",
       "1  9-13       9       13          7.7\n",
       "2   5-6       5        6          8.5\n",
       "3  3-23       3       23          9.3\n",
       "4  9-16       9       16          8.2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>total_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4-10</td>\n",
       "      <td>2095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-21</td>\n",
       "      <td>2403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7-24</td>\n",
       "      <td>2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6-18</td>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8-8</td>\n",
       "      <td>1584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  total_votes\n",
       "0  4-10         2095\n",
       "1  3-21         2403\n",
       "2  7-24         2040\n",
       "3  6-18         1769\n",
       "4   8-8         1584"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total votes and imdb ratings data are split between files. There is a common column called id. We can join the two dataframes together using the common column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>total_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5-1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9-13</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5-6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-23</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>9.3</td>\n",
       "      <td>3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9-16</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>5-21</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2-13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>9-6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2-2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>3-4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  season  episode  imdb_rating  total_votes\n",
       "0     5-1       5        1          8.8         2501\n",
       "1    9-13       9       13          7.7         1394\n",
       "2     5-6       5        6          8.5         2018\n",
       "3    3-23       3       23          9.3         3010\n",
       "4    9-16       9       16          8.2         1572\n",
       "..    ...     ...      ...          ...          ...\n",
       "183  5-21       5       21          8.7         2032\n",
       "184  2-13       2       13          8.3         2363\n",
       "185   9-6       9        6          7.8         1455\n",
       "186   2-2       2        2          8.2         2736\n",
       "187   3-4       3        4          8.0         2311\n",
       "\n",
       "[188 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_join_office_df = pd.merge(df_1, df_2, on='id', how='inner')\n",
    "inner_join_office_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way you can combine datasets using common columns. We will leave that for the moment. If you want more information about merging data then see [this page](https://www.datasciencemadesimple.com/join-merge-data-frames-pandas-python/#:~:text=Merge%20%28%29%20Function%20in%20pandas%20is%20similar%20to,rows%20from%20both%20data%20frames%2C%20specify%20how%3D%20%E2%80%98outer%E2%80%99.) and the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "To get an overview of our data we can ask Python to 'describe our data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>total_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>188.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.468085</td>\n",
       "      <td>11.877660</td>\n",
       "      <td>8.257447</td>\n",
       "      <td>2126.648936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.386245</td>\n",
       "      <td>7.024855</td>\n",
       "      <td>0.538067</td>\n",
       "      <td>787.098275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>1393.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>1631.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>1952.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>2379.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>7934.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           season     episode  imdb_rating  total_votes\n",
       "count  188.000000  188.000000   188.000000   188.000000\n",
       "mean     5.468085   11.877660     8.257447  2126.648936\n",
       "std      2.386245    7.024855     0.538067   787.098275\n",
       "min      1.000000    1.000000     6.700000  1393.000000\n",
       "25%      3.000000    6.000000     7.900000  1631.500000\n",
       "50%      6.000000   11.500000     8.200000  1952.500000\n",
       "75%      7.250000   18.000000     8.600000  2379.000000\n",
       "max      9.000000   26.000000     9.700000  7934.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we can pull out specific statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season            5.468085\n",
       "episode          11.877660\n",
       "imdb_rating       8.257447\n",
       "total_votes    2126.648936\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the error triggered above due to pandas attempting to calculate the mean of the wrong type (i.e. non-numeric values). We can address that by only computing the mean of numeric values (see below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season            5.468085\n",
       "episode          11.877660\n",
       "imdb_rating       8.257447\n",
       "total_votes    2126.648936\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season                                                      1028\n",
       "episode                                                     2233\n",
       "title          PilotDiversity DayHealth CareThe AllianceBaske...\n",
       "imdb_rating                                               1552.4\n",
       "total_votes                                               399810\n",
       "air_date       2005-03-242005-03-292005-04-052005-04-122005-0...\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to what happened with `mean()`, `sum()` is adding all values in every observation of every attribute, regardless of their type. Can you see what happens with strings? And with dates?\n",
    "\n",
    "Again, we can only force to use numeric values only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season           1028.0\n",
       "episode          2233.0\n",
       "imdb_rating      1552.4\n",
       "total_votes    399810.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating these statistics for specific columns is straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.25744680851064"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['imdb_rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399810"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_votes'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting subsets\n",
    "\n",
    "We can even select more than one column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imdb_rating       8.257447\n",
       "total_votes    2126.648936\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['imdb_rating', 'total_votes']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two sets of squared brackets is needed because you are passing a list of the column names to the getitem dunder method of the pandas dataframe object (thank [this stackoverflow question](https://stackoverflow.com/questions/11285613/selecting-multiple-columns-in-a-pandas-dataframe)). You can also check out the pandas documentation on [indexing and selecting data](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#basics).\n",
    "\n",
    "You can also select by row and column name using the iloc method. You can specify the [row, column]. So to choose the value in the 2nd row and 4th column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2983"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the rows or all the columns are indicated by :. Such as,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Pilot\n",
       "1         Diversity Day\n",
       "2           Health Care\n",
       "3          The Alliance\n",
       "4            Basketball\n",
       "             ...       \n",
       "183       Stairmageddon\n",
       "184      Paper Airplane\n",
       "185    Livin' the Dream\n",
       "186            A.A.R.M.\n",
       "187              Finale\n",
       "Name: title, Length: 188, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season                   1\n",
       "episode                  3\n",
       "title          Health Care\n",
       "imdb_rating            7.9\n",
       "total_votes           2983\n",
       "air_date        2005-04-05\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use negative values in indexes to indicate 'from the end'. So, an index of [-10, :] returns the 10th from last row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season                  9\n",
       "episode                14\n",
       "title           Vandalism\n",
       "imdb_rating           7.6\n",
       "total_votes          1402\n",
       "air_date       2013-01-31\n",
       "Name: 178, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[-10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using tail, we could ask for the last 10 rows with an index of [-10:, :]. I read : as 'and everything else' in these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>title</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>air_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>Stairmageddon</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1484</td>\n",
       "      <td>2013-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>Paper Airplane</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1482</td>\n",
       "      <td>2013-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>Livin' the Dream</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2041</td>\n",
       "      <td>2013-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>A.A.R.M.</td>\n",
       "      <td>9.3</td>\n",
       "      <td>2860</td>\n",
       "      <td>2013-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>Finale</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7934</td>\n",
       "      <td>2013-05-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season  episode             title  imdb_rating  total_votes    air_date\n",
       "183       9       19     Stairmageddon          8.0         1484  2013-04-11\n",
       "184       9       20    Paper Airplane          8.0         1482  2013-04-25\n",
       "185       9       21  Livin' the Dream          8.9         2041  2013-05-02\n",
       "186       9       22          A.A.R.M.          9.3         2860  2013-05-09\n",
       "187       9       23            Finale          9.7         7934  2013-05-16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[-5:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>title</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>air_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>Stairmageddon</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1484</td>\n",
       "      <td>2013-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>Paper Airplane</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1482</td>\n",
       "      <td>2013-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>Livin' the Dream</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2041</td>\n",
       "      <td>2013-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>A.A.R.M.</td>\n",
       "      <td>9.3</td>\n",
       "      <td>2860</td>\n",
       "      <td>2013-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>Finale</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7934</td>\n",
       "      <td>2013-05-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season  episode             title  imdb_rating  total_votes    air_date\n",
       "183       9       19     Stairmageddon          8.0         1484  2013-04-11\n",
       "184       9       20    Paper Airplane          8.0         1482  2013-04-25\n",
       "185       9       21  Livin' the Dream          8.9         2041  2013-05-02\n",
       "186       9       22          A.A.R.M.          9.3         2860  2013-05-09\n",
       "187       9       23            Finale          9.7         7934  2013-05-16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the row is shown on the left. That will stop you getting lost in slices of the data. \n",
    "\n",
    "For the top ten rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>title</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>air_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3706</td>\n",
       "      <td>2005-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Diversity Day</td>\n",
       "      <td>8.3</td>\n",
       "      <td>3566</td>\n",
       "      <td>2005-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2983</td>\n",
       "      <td>2005-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The Alliance</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2886</td>\n",
       "      <td>2005-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3179</td>\n",
       "      <td>2005-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Hot Girl</td>\n",
       "      <td>7.8</td>\n",
       "      <td>2852</td>\n",
       "      <td>2005-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The Dundies</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3213</td>\n",
       "      <td>2005-09-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Sexual Harassment</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2736</td>\n",
       "      <td>2005-09-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Office Olympics</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2742</td>\n",
       "      <td>2005-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>The Fire</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2713</td>\n",
       "      <td>2005-10-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  episode              title  imdb_rating  total_votes    air_date\n",
       "0       1        1              Pilot          7.6         3706  2005-03-24\n",
       "1       1        2      Diversity Day          8.3         3566  2005-03-29\n",
       "2       1        3        Health Care          7.9         2983  2005-04-05\n",
       "3       1        4       The Alliance          8.1         2886  2005-04-12\n",
       "4       1        5         Basketball          8.4         3179  2005-04-19\n",
       "5       1        6           Hot Girl          7.8         2852  2005-04-26\n",
       "6       2        1        The Dundies          8.7         3213  2005-09-20\n",
       "7       2        2  Sexual Harassment          8.2         2736  2005-09-27\n",
       "8       2        3    Office Olympics          8.4         2742  2005-10-04\n",
       "9       2        4           The Fire          8.4         2713  2005-10-11"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can run methods on these slices. We could, if we wanted to, calculate the mean imdb rating of only the first and last 100 episodes. _Note_ the indexing starts at 0 so we want the column index of 3 (0:season, 1:episode, 2:title, 3:imdb_rating)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.483"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:100,3].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.062"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[-100:,3].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are unsure how many rows you have then the count method comes to the rescue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[-100:,3].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>total_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>188.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.468085</td>\n",
       "      <td>11.877660</td>\n",
       "      <td>8.257447</td>\n",
       "      <td>2126.648936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.386245</td>\n",
       "      <td>7.024855</td>\n",
       "      <td>0.538067</td>\n",
       "      <td>787.098275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>1393.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>1631.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>1952.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>2379.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>7934.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           season     episode  imdb_rating  total_votes\n",
       "count  188.000000  188.000000   188.000000   188.000000\n",
       "mean     5.468085   11.877660     8.257447  2126.648936\n",
       "std      2.386245    7.024855     0.538067   787.098275\n",
       "min      1.000000    1.000000     6.700000  1393.000000\n",
       "25%      3.000000    6.000000     7.900000  1631.500000\n",
       "50%      6.000000   11.500000     8.200000  1952.500000\n",
       "75%      7.250000   18.000000     8.600000  2379.000000\n",
       "max      9.000000   26.000000     9.700000  7934.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like the last 100 episodes were less good than the first 100. I guess that is why it was cancelled.\n",
    "\n",
    "Our data is organised by season. Looking at the average by season might help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.436364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.573913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.219231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.956522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        imdb_rating\n",
       "season             \n",
       "1          8.016667\n",
       "2          8.436364\n",
       "3          8.573913\n",
       "4          8.600000\n",
       "5          8.492308\n",
       "6          8.219231\n",
       "7          8.316667\n",
       "8          7.666667\n",
       "9          7.956522"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['season', 'imdb_rating']].groupby('season').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line groups our dataframe by values in the season column and then displays the mean for each group. Pretty nifty.\n",
    "\n",
    "Season 8 looks pretty bad. We can look at just the rows for season 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>title</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>air_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>The List</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1829</td>\n",
       "      <td>2011-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>The Incentive</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1668</td>\n",
       "      <td>2011-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Lotto</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1601</td>\n",
       "      <td>2011-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Garden Party</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1717</td>\n",
       "      <td>2011-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>Spooked</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1543</td>\n",
       "      <td>2011-10-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>Doomsday</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1476</td>\n",
       "      <td>2011-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>Pam's Replacement</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1563</td>\n",
       "      <td>2011-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Gettysburg</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1584</td>\n",
       "      <td>2011-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>Mrs. California</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1553</td>\n",
       "      <td>2011-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>Christmas Wishes</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1547</td>\n",
       "      <td>2011-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>Trivia</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1488</td>\n",
       "      <td>2012-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Pool Party</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1612</td>\n",
       "      <td>2012-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>Jury Duty</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1478</td>\n",
       "      <td>2012-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>Special Project</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1432</td>\n",
       "      <td>2012-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1522</td>\n",
       "      <td>2012-02-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>After Hours</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1567</td>\n",
       "      <td>2012-02-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>Test the Store</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1478</td>\n",
       "      <td>2012-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>Last Day in Florida</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1429</td>\n",
       "      <td>2012-03-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>Get the Girl</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1642</td>\n",
       "      <td>2012-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>Welcome Party</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1489</td>\n",
       "      <td>2012-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>Angry Andy</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1585</td>\n",
       "      <td>2012-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>Fundraiser</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1453</td>\n",
       "      <td>2012-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>Turf War</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1393</td>\n",
       "      <td>2012-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>Free Family Portrait Studio</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1464</td>\n",
       "      <td>2012-05-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season  episode                        title  imdb_rating  total_votes  \\\n",
       "141       8        1                     The List          8.2         1829   \n",
       "142       8        2                The Incentive          8.2         1668   \n",
       "143       8        3                        Lotto          7.3         1601   \n",
       "144       8        4                 Garden Party          8.1         1717   \n",
       "145       8        5                      Spooked          7.6         1543   \n",
       "146       8        6                     Doomsday          7.8         1476   \n",
       "147       8        7            Pam's Replacement          7.7         1563   \n",
       "148       8        8                   Gettysburg          7.0         1584   \n",
       "149       8        9              Mrs. California          7.7         1553   \n",
       "150       8       10             Christmas Wishes          8.0         1547   \n",
       "151       8       11                       Trivia          7.9         1488   \n",
       "152       8       12                   Pool Party          8.0         1612   \n",
       "153       8       13                    Jury Duty          7.5         1478   \n",
       "154       8       14              Special Project          7.8         1432   \n",
       "155       8       15                  Tallahassee          7.9         1522   \n",
       "156       8       16                  After Hours          8.1         1567   \n",
       "157       8       17               Test the Store          7.8         1478   \n",
       "158       8       18          Last Day in Florida          7.8         1429   \n",
       "159       8       19                 Get the Girl          6.7         1642   \n",
       "160       8       20                Welcome Party          7.2         1489   \n",
       "161       8       21                   Angry Andy          7.1         1585   \n",
       "162       8       22                   Fundraiser          7.1         1453   \n",
       "163       8       23                     Turf War          7.7         1393   \n",
       "164       8       24  Free Family Portrait Studio          7.8         1464   \n",
       "\n",
       "       air_date  \n",
       "141  2011-09-22  \n",
       "142  2011-09-29  \n",
       "143  2011-10-06  \n",
       "144  2011-10-13  \n",
       "145  2011-10-27  \n",
       "146  2011-11-03  \n",
       "147  2011-11-10  \n",
       "148  2011-11-17  \n",
       "149  2011-12-01  \n",
       "150  2011-12-08  \n",
       "151  2012-01-12  \n",
       "152  2012-01-19  \n",
       "153  2012-02-02  \n",
       "154  2012-02-09  \n",
       "155  2012-02-16  \n",
       "156  2012-02-23  \n",
       "157  2012-03-01  \n",
       "158  2012-03-08  \n",
       "159  2012-03-15  \n",
       "160  2012-04-12  \n",
       "161  2012-04-19  \n",
       "162  2012-04-26  \n",
       "163  2012-05-03  \n",
       "164  2012-05-10  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['season'] == 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get an overview of the rating of all chapters within season 8 by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24.000000\n",
       "mean      7.666667\n",
       "std       0.405041\n",
       "min       6.700000\n",
       "25%       7.450000\n",
       "50%       7.800000\n",
       "75%       7.925000\n",
       "max       8.200000\n",
       "Name: imdb_rating, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['season'] == 8, 'imdb_rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "183    False\n",
       "184    False\n",
       "185    False\n",
       "186    False\n",
       "187    False\n",
       "Name: season, Length: 188, dtype: bool"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['season'] == 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally pretty bad, but there is clearly one very disliked episode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding columns\n",
    "\n",
    "We can add new columns pretty simply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>title</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>air_date</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3706</td>\n",
       "      <td>2005-03-24</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Diversity Day</td>\n",
       "      <td>8.3</td>\n",
       "      <td>3566</td>\n",
       "      <td>2005-03-29</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2983</td>\n",
       "      <td>2005-04-05</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The Alliance</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2886</td>\n",
       "      <td>2005-04-12</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3179</td>\n",
       "      <td>2005-04-19</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  episode          title  imdb_rating  total_votes    air_date   x\n",
       "0       1        1          Pilot          7.6         3706  2005-03-24  44\n",
       "1       1        2  Diversity Day          8.3         3566  2005-03-29  44\n",
       "2       1        3    Health Care          7.9         2983  2005-04-05  44\n",
       "3       1        4   The Alliance          8.1         2886  2005-04-12  44\n",
       "4       1        5     Basketball          8.4         3179  2005-04-19  44"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['x'] = 44\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new column can be an operation on other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>title</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>air_date</th>\n",
       "      <th>x</th>\n",
       "      <th>rating_div_total_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3706</td>\n",
       "      <td>2005-03-24</td>\n",
       "      <td>44</td>\n",
       "      <td>0.002051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Diversity Day</td>\n",
       "      <td>8.3</td>\n",
       "      <td>3566</td>\n",
       "      <td>2005-03-29</td>\n",
       "      <td>44</td>\n",
       "      <td>0.002328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2983</td>\n",
       "      <td>2005-04-05</td>\n",
       "      <td>44</td>\n",
       "      <td>0.002648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The Alliance</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2886</td>\n",
       "      <td>2005-04-12</td>\n",
       "      <td>44</td>\n",
       "      <td>0.002807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3179</td>\n",
       "      <td>2005-04-19</td>\n",
       "      <td>44</td>\n",
       "      <td>0.002642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  episode          title  imdb_rating  total_votes    air_date   x  \\\n",
       "0       1        1          Pilot          7.6         3706  2005-03-24  44   \n",
       "1       1        2  Diversity Day          8.3         3566  2005-03-29  44   \n",
       "2       1        3    Health Care          7.9         2983  2005-04-05  44   \n",
       "3       1        4   The Alliance          8.1         2886  2005-04-12  44   \n",
       "4       1        5     Basketball          8.4         3179  2005-04-19  44   \n",
       "\n",
       "   rating_div_total_votes  \n",
       "0                0.002051  \n",
       "1                0.002328  \n",
       "2                0.002648  \n",
       "3                0.002807  \n",
       "4                0.002642  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating_div_total_votes'] = df['imdb_rating'] / df['total_votes']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or as simple as adding one to every value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>title</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>air_date</th>\n",
       "      <th>x</th>\n",
       "      <th>rating_div_total_votes</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3706</td>\n",
       "      <td>2005-03-24</td>\n",
       "      <td>44</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Diversity Day</td>\n",
       "      <td>8.3</td>\n",
       "      <td>3566</td>\n",
       "      <td>2005-03-29</td>\n",
       "      <td>44</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2983</td>\n",
       "      <td>2005-04-05</td>\n",
       "      <td>44</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The Alliance</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2886</td>\n",
       "      <td>2005-04-12</td>\n",
       "      <td>44</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3179</td>\n",
       "      <td>2005-04-19</td>\n",
       "      <td>44</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  episode          title  imdb_rating  total_votes    air_date   x  \\\n",
       "0       1        1          Pilot          7.6         3706  2005-03-24  44   \n",
       "1       1        2  Diversity Day          8.3         3566  2005-03-29  44   \n",
       "2       1        3    Health Care          7.9         2983  2005-04-05  44   \n",
       "3       1        4   The Alliance          8.1         2886  2005-04-12  44   \n",
       "4       1        5     Basketball          8.4         3179  2005-04-19  44   \n",
       "\n",
       "   rating_div_total_votes  y  \n",
       "0                0.002051  2  \n",
       "1                0.002328  2  \n",
       "2                0.002648  2  \n",
       "3                0.002807  2  \n",
       "4                0.002642  2  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'] = df['season'] + 1\n",
    "df.iloc[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =  df['season'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing data\n",
    "\n",
    "Pandas supports writing out data frames to various formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mna_rep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfloat_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | Callable | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Sequence[Hashable] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mheader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool_t | list[str]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool_t'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mindex_label\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'IndexLabel | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'CompressionOptions'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mquoting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlineterminator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdate_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdoublequote\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool_t'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mescapechar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdecimal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'strict'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'StorageOptions'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'str | None'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Write object to a comma-separated values (csv) file.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "path_or_buf : str, path object, file-like object, or None, default None\n",
      "    String, path object (implementing os.PathLike[str]), or file-like\n",
      "    object implementing a write() function. If None, the result is\n",
      "    returned as a string. If a non-binary file object is passed, it should\n",
      "    be opened with `newline=''`, disabling universal newlines. If a binary\n",
      "    file object is passed, `mode` might need to contain a `'b'`.\n",
      "\n",
      "    .. versionchanged:: 1.2.0\n",
      "\n",
      "       Support for binary file objects was introduced.\n",
      "\n",
      "sep : str, default ','\n",
      "    String of length 1. Field delimiter for the output file.\n",
      "na_rep : str, default ''\n",
      "    Missing data representation.\n",
      "float_format : str, Callable, default None\n",
      "    Format string for floating point numbers. If a Callable is given, it takes\n",
      "    precedence over other numeric formatting parameters, like decimal.\n",
      "columns : sequence, optional\n",
      "    Columns to write.\n",
      "header : bool or list of str, default True\n",
      "    Write out the column names. If a list of strings is given it is\n",
      "    assumed to be aliases for the column names.\n",
      "index : bool, default True\n",
      "    Write row names (index).\n",
      "index_label : str or sequence, or False, default None\n",
      "    Column label for index column(s) if desired. If None is given, and\n",
      "    `header` and `index` are True, then the index names are used. A\n",
      "    sequence should be given if the object uses MultiIndex. If\n",
      "    False do not print fields for index names. Use index_label=False\n",
      "    for easier importing in R.\n",
      "mode : str, default 'w'\n",
      "    Python write mode. The available write modes are the same as\n",
      "    :py:func:`open`.\n",
      "encoding : str, optional\n",
      "    A string representing the encoding to use in the output file,\n",
      "    defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      "    is a non-binary file object.\n",
      "compression : str or dict, default 'infer'\n",
      "    For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      "    path-like, then detect compression from the following extensions: '.gz',\n",
      "    '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "    (otherwise no compression).\n",
      "    Set to ``None`` for no compression.\n",
      "    Can also be a dict with key ``'method'`` set\n",
      "    to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      "    key-value pairs are forwarded to\n",
      "    ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "    ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or\n",
      "    ``tarfile.TarFile``, respectively.\n",
      "    As an example, the following could be passed for faster compression and to create\n",
      "    a reproducible gzip archive:\n",
      "    ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      "\n",
      "    .. versionadded:: 1.5.0\n",
      "        Added support for `.tar` files.\n",
      "\n",
      "    .. versionchanged:: 1.0.0\n",
      "\n",
      "       May now be a dict with key 'method' as compression mode\n",
      "       and other entries as additional compression options if\n",
      "       compression mode is 'zip'.\n",
      "\n",
      "    .. versionchanged:: 1.1.0\n",
      "\n",
      "       Passing compression options as keys in dict is\n",
      "       supported for compression modes 'gzip', 'bz2', 'zstd', and 'zip'.\n",
      "\n",
      "    .. versionchanged:: 1.2.0\n",
      "\n",
      "        Compression is supported for binary file objects.\n",
      "\n",
      "    .. versionchanged:: 1.2.0\n",
      "\n",
      "        Previous versions forwarded dict entries for 'gzip' to\n",
      "        `gzip.open` instead of `gzip.GzipFile` which prevented\n",
      "        setting `mtime`.\n",
      "\n",
      "quoting : optional constant from csv module\n",
      "    Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      "    then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      "    will treat them as non-numeric.\n",
      "quotechar : str, default '\\\"'\n",
      "    String of length 1. Character used to quote fields.\n",
      "lineterminator : str, optional\n",
      "    The newline character or character sequence to use in the output\n",
      "    file. Defaults to `os.linesep`, which depends on the OS in which\n",
      "    this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      "\n",
      "    .. versionchanged:: 1.5.0\n",
      "\n",
      "        Previously was line_terminator, changed for consistency with\n",
      "        read_csv and the standard library 'csv' module.\n",
      "\n",
      "chunksize : int or None\n",
      "    Rows to write at a time.\n",
      "date_format : str, default None\n",
      "    Format string for datetime objects.\n",
      "doublequote : bool, default True\n",
      "    Control quoting of `quotechar` inside a field.\n",
      "escapechar : str, default None\n",
      "    String of length 1. Character used to escape `sep` and `quotechar`\n",
      "    when appropriate.\n",
      "decimal : str, default '.'\n",
      "    Character recognized as decimal separator. E.g. use ',' for\n",
      "    European data.\n",
      "errors : str, default 'strict'\n",
      "    Specifies how encoding and decoding errors are to be handled.\n",
      "    See the errors argument for :func:`open` for a full list\n",
      "    of options.\n",
      "\n",
      "    .. versionadded:: 1.1.0\n",
      "\n",
      "storage_options : dict, optional\n",
      "    Extra options that make sense for a particular storage connection, e.g.\n",
      "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "    are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "    URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "    forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "    details, and for more examples on storage options refer `here\n",
      "    <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "    highlight=storage_options#reading-writing-remote-files>`_.\n",
      "\n",
      "    .. versionadded:: 1.2.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "None or str\n",
      "    If path_or_buf is None, returns the resulting csv format as a\n",
      "    string. Otherwise returns None.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "read_csv : Load a CSV file into a DataFrame.\n",
      "to_excel : Write DataFrame to an Excel file.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      "...                    'mask': ['red', 'purple'],\n",
      "...                    'weapon': ['sai', 'bo staff']})\n",
      ">>> df.to_csv(index=False)\n",
      "'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      "\n",
      "Create 'out.zip' containing 'out.csv'\n",
      "\n",
      ">>> compression_opts = dict(method='zip',\n",
      "...                         archive_name='out.csv')  # doctest: +SKIP\n",
      ">>> df.to_csv('out.zip', index=False,\n",
      "...           compression=compression_opts)  # doctest: +SKIP\n",
      "\n",
      "To write a csv file to a new folder or nested folder you will first\n",
      "need to create it using either Pathlib or os:\n",
      "\n",
      ">>> from pathlib import Path  # doctest: +SKIP\n",
      ">>> filepath = Path('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      ">>> filepath.parent.mkdir(parents=True, exist_ok=True)  # doctest: +SKIP\n",
      ">>> df.to_csv(filepath)  # doctest: +SKIP\n",
      "\n",
      ">>> import os  # doctest: +SKIP\n",
      ">>> os.makedirs('folder/subfolder', exist_ok=True)  # doctest: +SKIP\n",
      ">>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/IM939/lib/python3.11/site-packages/pandas/core/generic.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "?df.to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can uncomment the code below to save your dataframe into a csv file. But before doing so, check that your `data/output` folder is empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('data/output/my_output_ratings.csv', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexcel_writer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msheet_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Sheet1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mna_rep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfloat_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Sequence[Hashable] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mheader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Sequence[Hashable] | bool_t'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool_t'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mindex_label\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'IndexLabel'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstartrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstartcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmerge_cells\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool_t'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minf_rep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'inf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfreeze_panes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'tuple[int, int] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'StorageOptions'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'None'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Write object to an Excel sheet.\n",
      "\n",
      "To write a single object to an Excel .xlsx file it is only necessary to\n",
      "specify a target file name. To write to multiple sheets it is necessary to\n",
      "create an `ExcelWriter` object with a target file name, and specify a sheet\n",
      "in the file to write to.\n",
      "\n",
      "Multiple sheets may be written to by specifying unique `sheet_name`.\n",
      "With all data written to the file it is necessary to save the changes.\n",
      "Note that creating an `ExcelWriter` object with a file name that already\n",
      "exists will result in the contents of the existing file being erased.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "excel_writer : path-like, file-like, or ExcelWriter object\n",
      "    File path or existing ExcelWriter.\n",
      "sheet_name : str, default 'Sheet1'\n",
      "    Name of sheet which will contain DataFrame.\n",
      "na_rep : str, default ''\n",
      "    Missing data representation.\n",
      "float_format : str, optional\n",
      "    Format string for floating point numbers. For example\n",
      "    ``float_format=\"%.2f\"`` will format 0.1234 to 0.12.\n",
      "columns : sequence or list of str, optional\n",
      "    Columns to write.\n",
      "header : bool or list of str, default True\n",
      "    Write out the column names. If a list of string is given it is\n",
      "    assumed to be aliases for the column names.\n",
      "index : bool, default True\n",
      "    Write row names (index).\n",
      "index_label : str or sequence, optional\n",
      "    Column label for index column(s) if desired. If not specified, and\n",
      "    `header` and `index` are True, then the index names are used. A\n",
      "    sequence should be given if the DataFrame uses MultiIndex.\n",
      "startrow : int, default 0\n",
      "    Upper left cell row to dump data frame.\n",
      "startcol : int, default 0\n",
      "    Upper left cell column to dump data frame.\n",
      "engine : str, optional\n",
      "    Write engine to use, 'openpyxl' or 'xlsxwriter'. You can also set this\n",
      "    via the options ``io.excel.xlsx.writer`` or\n",
      "    ``io.excel.xlsm.writer``.\n",
      "\n",
      "merge_cells : bool, default True\n",
      "    Write MultiIndex and Hierarchical Rows as merged cells.\n",
      "inf_rep : str, default 'inf'\n",
      "    Representation for infinity (there is no native representation for\n",
      "    infinity in Excel).\n",
      "freeze_panes : tuple of int (length 2), optional\n",
      "    Specifies the one-based bottommost row and rightmost column that\n",
      "    is to be frozen.\n",
      "storage_options : dict, optional\n",
      "    Extra options that make sense for a particular storage connection, e.g.\n",
      "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "    are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "    URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "    forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "    details, and for more examples on storage options refer `here\n",
      "    <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "    highlight=storage_options#reading-writing-remote-files>`_.\n",
      "\n",
      "    .. versionadded:: 1.2.0\n",
      "\n",
      "See Also\n",
      "--------\n",
      "to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "ExcelWriter : Class for writing DataFrame objects into excel sheets.\n",
      "read_excel : Read an Excel file into a pandas DataFrame.\n",
      "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "io.formats.style.Styler.to_excel : Add styles to Excel sheet.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "For compatibility with :meth:`~DataFrame.to_csv`,\n",
      "to_excel serializes lists and dicts to strings before writing.\n",
      "\n",
      "Once a workbook has been saved it is not possible to write further\n",
      "data without rewriting the whole workbook.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "Create, write to and save a workbook:\n",
      "\n",
      ">>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      "...                    index=['row 1', 'row 2'],\n",
      "...                    columns=['col 1', 'col 2'])\n",
      ">>> df1.to_excel(\"output.xlsx\")  # doctest: +SKIP\n",
      "\n",
      "To specify the sheet name:\n",
      "\n",
      ">>> df1.to_excel(\"output.xlsx\",\n",
      "...              sheet_name='Sheet_name_1')  # doctest: +SKIP\n",
      "\n",
      "If you wish to write to more than one sheet in the workbook, it is\n",
      "necessary to specify an ExcelWriter object:\n",
      "\n",
      ">>> df2 = df1.copy()\n",
      ">>> with pd.ExcelWriter('output.xlsx') as writer:  # doctest: +SKIP\n",
      "...     df1.to_excel(writer, sheet_name='Sheet_name_1')\n",
      "...     df2.to_excel(writer, sheet_name='Sheet_name_2')\n",
      "\n",
      "ExcelWriter can also be used to append to an existing Excel file:\n",
      "\n",
      ">>> with pd.ExcelWriter('output.xlsx',\n",
      "...                     mode='a') as writer:  # doctest: +SKIP\n",
      "...     df.to_excel(writer, sheet_name='Sheet_name_3')\n",
      "\n",
      "To set the library that is used to write the Excel file,\n",
      "you can pass the `engine` keyword (the default engine is\n",
      "automatically chosen depending on the file extension):\n",
      "\n",
      ">>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  # doctest: +SKIP\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/IM939/lib/python3.11/site-packages/pandas/core/generic.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "?df.to_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can uncomment the code below to save your dataframe into an excel file. But before doing so, check that your `data/output` folder is empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel('data/output/my_output_ratings.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
