{
  "hash": "54f9e170c891085a292f8c7c8db744f2",
  "result": {
    "markdown": "# Lab: Dimension reduction (2)\n\nIn the previous lab, we learned how to work with dimension reduction in a relatively simple dataset. In this lab we are going to work with a much larger dataset: a subset of the US Census & Crime data [@misc_communities_and_crime_183]. Details about the various variables can be found [here](http://archive.ics.uci.edu/ml/datasets/communities+and+crime).\n\nHow can we tackle a dataset with 100 different dimensions? We try using PCA and clustering. There is a lot you can do with this dataset. We encourage you to dig in. Try and find some interesting patterns in the data. Even upload your findings to the Teams channel and discuss.\n\n## Data\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\ndf = pd.read_csv('data/censusCrimeClean.csv')\n\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>communityname</th>\n      <th>fold</th>\n      <th>population</th>\n      <th>householdsize</th>\n      <th>racepctblack</th>\n      <th>racePctWhite</th>\n      <th>racePctAsian</th>\n      <th>racePctHisp</th>\n      <th>agePct12t21</th>\n      <th>agePct12t29</th>\n      <th>...</th>\n      <th>NumStreet</th>\n      <th>PctForeignBorn</th>\n      <th>PctBornSameState</th>\n      <th>PctSameHouse85</th>\n      <th>PctSameCity85</th>\n      <th>PctSameState85</th>\n      <th>LandArea</th>\n      <th>PopDens</th>\n      <th>PctUsePubTrans</th>\n      <th>ViolentCrimesPerPop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Lakewoodcity</td>\n      <td>1</td>\n      <td>0.19</td>\n      <td>0.33</td>\n      <td>0.02</td>\n      <td>0.90</td>\n      <td>0.12</td>\n      <td>0.17</td>\n      <td>0.34</td>\n      <td>0.47</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.12</td>\n      <td>0.42</td>\n      <td>0.50</td>\n      <td>0.51</td>\n      <td>0.64</td>\n      <td>0.12</td>\n      <td>0.26</td>\n      <td>0.20</td>\n      <td>0.20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Tukwilacity</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>0.16</td>\n      <td>0.12</td>\n      <td>0.74</td>\n      <td>0.45</td>\n      <td>0.07</td>\n      <td>0.26</td>\n      <td>0.59</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.21</td>\n      <td>0.50</td>\n      <td>0.34</td>\n      <td>0.60</td>\n      <td>0.52</td>\n      <td>0.02</td>\n      <td>0.12</td>\n      <td>0.45</td>\n      <td>0.67</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Aberdeentown</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>0.42</td>\n      <td>0.49</td>\n      <td>0.56</td>\n      <td>0.17</td>\n      <td>0.04</td>\n      <td>0.39</td>\n      <td>0.47</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.14</td>\n      <td>0.49</td>\n      <td>0.54</td>\n      <td>0.67</td>\n      <td>0.56</td>\n      <td>0.01</td>\n      <td>0.21</td>\n      <td>0.02</td>\n      <td>0.43</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Willingborotownship</td>\n      <td>1</td>\n      <td>0.04</td>\n      <td>0.77</td>\n      <td>1.00</td>\n      <td>0.08</td>\n      <td>0.12</td>\n      <td>0.10</td>\n      <td>0.51</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.19</td>\n      <td>0.30</td>\n      <td>0.73</td>\n      <td>0.64</td>\n      <td>0.65</td>\n      <td>0.02</td>\n      <td>0.39</td>\n      <td>0.28</td>\n      <td>0.12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bethlehemtownship</td>\n      <td>1</td>\n      <td>0.01</td>\n      <td>0.55</td>\n      <td>0.02</td>\n      <td>0.95</td>\n      <td>0.09</td>\n      <td>0.05</td>\n      <td>0.38</td>\n      <td>0.38</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.11</td>\n      <td>0.72</td>\n      <td>0.64</td>\n      <td>0.61</td>\n      <td>0.53</td>\n      <td>0.04</td>\n      <td>0.09</td>\n      <td>0.02</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1989</th>\n      <td>TempleTerracecity</td>\n      <td>10</td>\n      <td>0.01</td>\n      <td>0.40</td>\n      <td>0.10</td>\n      <td>0.87</td>\n      <td>0.12</td>\n      <td>0.16</td>\n      <td>0.43</td>\n      <td>0.51</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.22</td>\n      <td>0.28</td>\n      <td>0.34</td>\n      <td>0.48</td>\n      <td>0.39</td>\n      <td>0.01</td>\n      <td>0.28</td>\n      <td>0.05</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>1990</th>\n      <td>Seasidecity</td>\n      <td>10</td>\n      <td>0.05</td>\n      <td>0.96</td>\n      <td>0.46</td>\n      <td>0.28</td>\n      <td>0.83</td>\n      <td>0.32</td>\n      <td>0.69</td>\n      <td>0.86</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.53</td>\n      <td>0.25</td>\n      <td>0.17</td>\n      <td>0.10</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.37</td>\n      <td>0.20</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>1991</th>\n      <td>Waterburytown</td>\n      <td>10</td>\n      <td>0.16</td>\n      <td>0.37</td>\n      <td>0.25</td>\n      <td>0.69</td>\n      <td>0.04</td>\n      <td>0.25</td>\n      <td>0.35</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>0.02</td>\n      <td>0.25</td>\n      <td>0.68</td>\n      <td>0.61</td>\n      <td>0.79</td>\n      <td>0.76</td>\n      <td>0.08</td>\n      <td>0.32</td>\n      <td>0.18</td>\n      <td>0.23</td>\n    </tr>\n    <tr>\n      <th>1992</th>\n      <td>Walthamcity</td>\n      <td>10</td>\n      <td>0.08</td>\n      <td>0.51</td>\n      <td>0.06</td>\n      <td>0.87</td>\n      <td>0.22</td>\n      <td>0.10</td>\n      <td>0.58</td>\n      <td>0.74</td>\n      <td>...</td>\n      <td>0.01</td>\n      <td>0.45</td>\n      <td>0.64</td>\n      <td>0.54</td>\n      <td>0.59</td>\n      <td>0.52</td>\n      <td>0.03</td>\n      <td>0.38</td>\n      <td>0.33</td>\n      <td>0.19</td>\n    </tr>\n    <tr>\n      <th>1993</th>\n      <td>Ontariocity</td>\n      <td>10</td>\n      <td>0.20</td>\n      <td>0.78</td>\n      <td>0.14</td>\n      <td>0.46</td>\n      <td>0.24</td>\n      <td>0.77</td>\n      <td>0.50</td>\n      <td>0.62</td>\n      <td>...</td>\n      <td>0.08</td>\n      <td>0.68</td>\n      <td>0.50</td>\n      <td>0.34</td>\n      <td>0.35</td>\n      <td>0.68</td>\n      <td>0.11</td>\n      <td>0.30</td>\n      <td>0.05</td>\n      <td>0.48</td>\n    </tr>\n  </tbody>\n</table>\n<p>1994 rows × 102 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: callout-caution\n\n## Do-this-yourself: Let's say \"hi\" to the data\n\nYou have probably learnt by now that the best start to working with a new data set is to get to know it. What would be a good way to approach this?\n\nA few steps we always take:\n- Use the internal spreadsheet viewer in JupyterLab, go into the data folder and have a look at the data.\n- Check the size of the dataset. Do you remember how to look at the `shape` of a dataset?\n- Get a summary of the data, observe the *descriptive* statistics.\n- Check the data types and see if there are mixes of different types, such as numerical, categorical, textual, etc..\n- Create a visualisation to get a first peek into the relations. Think about the number of features. Is a visualisation feasible?\n\n:::\n  \n\n::: callout-caution\n\n## Do-this-yourself: Check if we need to do any normalisation for this case?\n\nWhat are the descriptive statistics look like, see if we need to do anything more?\n\nUsually a standardisation is recommended before you apply PCA on a dataset. Here is that link again -- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n\n:::\n\n## Principal Component Analysis\n\n\n**Note for the above:** In case you wondered, we have done some cleaning and preprocessing on this data to make things easier for you, so normalisation might not be needed or at least won't make a lot of difference to the results. But the real life will always be much more messier.\n\nOK, you probably have noticed that there is a lot of data features we have here. Let's start experimenting with the PCA technique and see what it could surface. Maybe it will help us reduce the dimensionality a little but and tell us something about the features.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nfrom sklearn.decomposition import PCA\n\nn_components = 2\n \npca = PCA(n_components=n_components)\ndf_pca = pca.fit(df.iloc[:, 1:])\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndf_pca.explained_variance_ratio_\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\narray([0.67387831, 0.08863102])\n```\n:::\n:::\n\n\n::: callout-caution\n\n## What do these numbers mean?\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndf_pca_vals = pca.fit_transform(df.iloc[:,1:])\ndf['c1'] = [item[0] for item in df_pca_vals]\ndf['c2'] = [item[1] for item in df_pca_vals]\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nimport seaborn as sns\nsns.scatterplot(data = df, x = 'c1', y = 'c2')\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n<Axes: xlabel='c1', ylabel='c2'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_4_2_Crime_files/figure-html/cell-6-output-2.png){width=587 height=432}\n:::\n:::\n\n\n\n\nHmm, that looks problematic. What is going on? When you see patterns like this, you will need to take a step back and look at everything closely.\n\nWe should look at the component loadings. Though there are going to be over 200 of them. We can put them into a Pandas dataframe and then sort them.\n\n:::\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndata = {'columns' : df.columns[1:102],\n        'component 1' : df_pca.components_[0],\n        'component 2' : df_pca.components_[1]}\n\n\nloadings = pd.DataFrame(data)\nloadings.sort_values(by=['component 1'], ascending=False, key=abs) \n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>columns</th>\n      <th>component 1</th>\n      <th>component 2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fold</td>\n      <td>0.999788</td>\n      <td>-0.016430</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>pctUrban</td>\n      <td>0.004944</td>\n      <td>0.146079</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>PctOccupManu</td>\n      <td>-0.004403</td>\n      <td>-0.132659</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>RentHighQ</td>\n      <td>0.004078</td>\n      <td>0.188187</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>medIncome</td>\n      <td>0.003932</td>\n      <td>0.185649</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>PctForeignBorn</td>\n      <td>0.000076</td>\n      <td>0.024639</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>racepctblack</td>\n      <td>0.000066</td>\n      <td>-0.130905</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>racePctAsian</td>\n      <td>0.000064</td>\n      <td>0.061561</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>PctUsePubTrans</td>\n      <td>0.000037</td>\n      <td>0.036078</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>racePctHisp</td>\n      <td>-0.000002</td>\n      <td>-0.064135</td>\n    </tr>\n  </tbody>\n</table>\n<p>101 rows × 3 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nloadings.sort_values(by=['component 2'], ascending=False) \n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>columns</th>\n      <th>component 1</th>\n      <th>component 2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>85</th>\n      <td>RentHighQ</td>\n      <td>0.004078</td>\n      <td>0.188187</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>medIncome</td>\n      <td>0.003932</td>\n      <td>0.185649</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>PctYoungKids2Par</td>\n      <td>0.003818</td>\n      <td>0.178675</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>medFamInc</td>\n      <td>0.003025</td>\n      <td>0.177225</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>PctKids2Par</td>\n      <td>0.002385</td>\n      <td>0.169581</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>PctIlleg</td>\n      <td>-0.001022</td>\n      <td>-0.153504</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>PctNotHSGrad</td>\n      <td>-0.002967</td>\n      <td>-0.158646</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>pctWPubAsst</td>\n      <td>-0.003697</td>\n      <td>-0.173593</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>PctPopUnderPov</td>\n      <td>-0.003594</td>\n      <td>-0.190548</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>PctHousNoPhone</td>\n      <td>-0.001759</td>\n      <td>-0.198116</td>\n    </tr>\n  </tbody>\n</table>\n<p>101 rows × 3 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: callout-caution\n\nDo you notice anything extraordinary within these variable loadings?\n\nRemember, the variable loadings tell us to what extent the information encoded along a principal component axis is determined by a single variable. In other words, how important a variable is. Haev a look and see if anything is too problematic here.\n\n:::\n\n\n\nThe fold variable is messing with our PCA. What does that variable look like.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndf.fold.value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nfold\n1     200\n2     200\n3     200\n4     200\n5     199\n6     199\n7     199\n8     199\n9     199\n10    199\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndf['fold'].unique()\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\narray([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n```\n:::\n:::\n\n\nAha! It looks to be some sort of categorical variable. Looking into the dataset more, it is actually a variable used for cross tabling.\n\nWe should not include this variable in our analysis.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ndf.iloc[:, 2:-2]\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>population</th>\n      <th>householdsize</th>\n      <th>racepctblack</th>\n      <th>racePctWhite</th>\n      <th>racePctAsian</th>\n      <th>racePctHisp</th>\n      <th>agePct12t21</th>\n      <th>agePct12t29</th>\n      <th>agePct16t24</th>\n      <th>agePct65up</th>\n      <th>...</th>\n      <th>NumStreet</th>\n      <th>PctForeignBorn</th>\n      <th>PctBornSameState</th>\n      <th>PctSameHouse85</th>\n      <th>PctSameCity85</th>\n      <th>PctSameState85</th>\n      <th>LandArea</th>\n      <th>PopDens</th>\n      <th>PctUsePubTrans</th>\n      <th>ViolentCrimesPerPop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.19</td>\n      <td>0.33</td>\n      <td>0.02</td>\n      <td>0.90</td>\n      <td>0.12</td>\n      <td>0.17</td>\n      <td>0.34</td>\n      <td>0.47</td>\n      <td>0.29</td>\n      <td>0.32</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.12</td>\n      <td>0.42</td>\n      <td>0.50</td>\n      <td>0.51</td>\n      <td>0.64</td>\n      <td>0.12</td>\n      <td>0.26</td>\n      <td>0.20</td>\n      <td>0.20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00</td>\n      <td>0.16</td>\n      <td>0.12</td>\n      <td>0.74</td>\n      <td>0.45</td>\n      <td>0.07</td>\n      <td>0.26</td>\n      <td>0.59</td>\n      <td>0.35</td>\n      <td>0.27</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.21</td>\n      <td>0.50</td>\n      <td>0.34</td>\n      <td>0.60</td>\n      <td>0.52</td>\n      <td>0.02</td>\n      <td>0.12</td>\n      <td>0.45</td>\n      <td>0.67</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00</td>\n      <td>0.42</td>\n      <td>0.49</td>\n      <td>0.56</td>\n      <td>0.17</td>\n      <td>0.04</td>\n      <td>0.39</td>\n      <td>0.47</td>\n      <td>0.28</td>\n      <td>0.32</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.14</td>\n      <td>0.49</td>\n      <td>0.54</td>\n      <td>0.67</td>\n      <td>0.56</td>\n      <td>0.01</td>\n      <td>0.21</td>\n      <td>0.02</td>\n      <td>0.43</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.04</td>\n      <td>0.77</td>\n      <td>1.00</td>\n      <td>0.08</td>\n      <td>0.12</td>\n      <td>0.10</td>\n      <td>0.51</td>\n      <td>0.50</td>\n      <td>0.34</td>\n      <td>0.21</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.19</td>\n      <td>0.30</td>\n      <td>0.73</td>\n      <td>0.64</td>\n      <td>0.65</td>\n      <td>0.02</td>\n      <td>0.39</td>\n      <td>0.28</td>\n      <td>0.12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.01</td>\n      <td>0.55</td>\n      <td>0.02</td>\n      <td>0.95</td>\n      <td>0.09</td>\n      <td>0.05</td>\n      <td>0.38</td>\n      <td>0.38</td>\n      <td>0.23</td>\n      <td>0.36</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.11</td>\n      <td>0.72</td>\n      <td>0.64</td>\n      <td>0.61</td>\n      <td>0.53</td>\n      <td>0.04</td>\n      <td>0.09</td>\n      <td>0.02</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1989</th>\n      <td>0.01</td>\n      <td>0.40</td>\n      <td>0.10</td>\n      <td>0.87</td>\n      <td>0.12</td>\n      <td>0.16</td>\n      <td>0.43</td>\n      <td>0.51</td>\n      <td>0.35</td>\n      <td>0.30</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.22</td>\n      <td>0.28</td>\n      <td>0.34</td>\n      <td>0.48</td>\n      <td>0.39</td>\n      <td>0.01</td>\n      <td>0.28</td>\n      <td>0.05</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>1990</th>\n      <td>0.05</td>\n      <td>0.96</td>\n      <td>0.46</td>\n      <td>0.28</td>\n      <td>0.83</td>\n      <td>0.32</td>\n      <td>0.69</td>\n      <td>0.86</td>\n      <td>0.73</td>\n      <td>0.14</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.53</td>\n      <td>0.25</td>\n      <td>0.17</td>\n      <td>0.10</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.37</td>\n      <td>0.20</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>1991</th>\n      <td>0.16</td>\n      <td>0.37</td>\n      <td>0.25</td>\n      <td>0.69</td>\n      <td>0.04</td>\n      <td>0.25</td>\n      <td>0.35</td>\n      <td>0.50</td>\n      <td>0.31</td>\n      <td>0.54</td>\n      <td>...</td>\n      <td>0.02</td>\n      <td>0.25</td>\n      <td>0.68</td>\n      <td>0.61</td>\n      <td>0.79</td>\n      <td>0.76</td>\n      <td>0.08</td>\n      <td>0.32</td>\n      <td>0.18</td>\n      <td>0.23</td>\n    </tr>\n    <tr>\n      <th>1992</th>\n      <td>0.08</td>\n      <td>0.51</td>\n      <td>0.06</td>\n      <td>0.87</td>\n      <td>0.22</td>\n      <td>0.10</td>\n      <td>0.58</td>\n      <td>0.74</td>\n      <td>0.63</td>\n      <td>0.41</td>\n      <td>...</td>\n      <td>0.01</td>\n      <td>0.45</td>\n      <td>0.64</td>\n      <td>0.54</td>\n      <td>0.59</td>\n      <td>0.52</td>\n      <td>0.03</td>\n      <td>0.38</td>\n      <td>0.33</td>\n      <td>0.19</td>\n    </tr>\n    <tr>\n      <th>1993</th>\n      <td>0.20</td>\n      <td>0.78</td>\n      <td>0.14</td>\n      <td>0.46</td>\n      <td>0.24</td>\n      <td>0.77</td>\n      <td>0.50</td>\n      <td>0.62</td>\n      <td>0.40</td>\n      <td>0.17</td>\n      <td>...</td>\n      <td>0.08</td>\n      <td>0.68</td>\n      <td>0.50</td>\n      <td>0.34</td>\n      <td>0.35</td>\n      <td>0.68</td>\n      <td>0.11</td>\n      <td>0.30</td>\n      <td>0.05</td>\n      <td>0.48</td>\n    </tr>\n  </tbody>\n</table>\n<p>1994 rows × 100 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfrom sklearn.decomposition import PCA\n\nn_components = 2\n\npca_no_fold = PCA(n_components=n_components)\ndf_pca_no_fold = pca_no_fold.fit(df.iloc[:, 2:-2])\n\ndf_pca_vals = pca_no_fold.fit_transform(df.iloc[:, 2:-2])\n\ndf['c1_no_fold'] = [item[0] for item in df_pca_vals]\ndf['c2_no_fold'] = [item[1] for item in df_pca_vals]\n\nsns.scatterplot(data = df, x = 'c1_no_fold', y = 'c2_no_fold')\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n<Axes: xlabel='c1_no_fold', ylabel='c2_no_fold'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_4_2_Crime_files/figure-html/cell-12-output-2.png){width=587 height=429}\n:::\n:::\n\n\nHow do our component loadings look?\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ndata = {'columns' : df.iloc[:, 2:-4].columns,\n        'component 1' : df_pca_no_fold.components_[0],\n        'component 2' : df_pca_no_fold.components_[1]}\n\n\nloadings = pd.DataFrame(data)\nloadings_sorted = loadings.sort_values(by=['component 1'], ascending=False)\nloadings_sorted.iloc[1:10,:]\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>columns</th>\n      <th>component 1</th>\n      <th>component 2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>medIncome</td>\n      <td>0.185822</td>\n      <td>0.040774</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>PctYoungKids2Par</td>\n      <td>0.178807</td>\n      <td>-0.017237</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>medFamInc</td>\n      <td>0.177283</td>\n      <td>0.031895</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>PctKids2Par</td>\n      <td>0.169533</td>\n      <td>-0.042621</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>PctFam2Par</td>\n      <td>0.163277</td>\n      <td>-0.031094</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>RentLowQ</td>\n      <td>0.163120</td>\n      <td>0.119274</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>MedRent</td>\n      <td>0.163120</td>\n      <td>0.106135</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>OwnOccMedVal</td>\n      <td>0.159850</td>\n      <td>0.135830</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>RentMedian</td>\n      <td>0.159605</td>\n      <td>0.113360</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nloadings_sorted = loadings.sort_values(by=['component 2'], ascending=False)\nloadings_sorted.iloc[1:10,:]\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>columns</th>\n      <th>component 1</th>\n      <th>component 2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>59</th>\n      <td>PctRecImmig10</td>\n      <td>-0.000556</td>\n      <td>0.253476</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>PctRecImmig5</td>\n      <td>-0.000901</td>\n      <td>0.252463</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>PctRecentImmig</td>\n      <td>0.001797</td>\n      <td>0.248239</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>PctForeignBorn</td>\n      <td>0.024743</td>\n      <td>0.241783</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>PctNotSpeakEnglWell</td>\n      <td>-0.048595</td>\n      <td>0.207575</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>racePctHisp</td>\n      <td>-0.063868</td>\n      <td>0.187826</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>PctPersDenseHous</td>\n      <td>-0.087193</td>\n      <td>0.184704</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>pctUrban</td>\n      <td>0.146557</td>\n      <td>0.183317</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>racePctAsian</td>\n      <td>0.061547</td>\n      <td>0.160710</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nInteresting that our first component variables are income related whereas our second component variables are immigration related. If we look at the projections of the model, coloured by Crime, what do we see?\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nsns.scatterplot(data = df,\n                x = 'c1_no_fold',\n                y = 'c2_no_fold',\n                hue = 'ViolentCrimesPerPop',\n                size = 'ViolentCrimesPerPop')\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n<Axes: xlabel='c1_no_fold', ylabel='c2_no_fold'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_4_2_Crime_files/figure-html/cell-15-output-2.png){width=587 height=429}\n:::\n:::\n\n\n## Clustering\n\nWhat about clustering using these `income` and `immigration` components?\n\n### Defining number of clusters\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nfrom sklearn.cluster import KMeans\n\nks = range(1, 10)\ninertias = []\nfor k in ks:\n    # Create a KMeans instance with k clusters: model\n    model = KMeans(n_clusters=k, n_init = 10)\n    \n    # Fit model to samples\n    model.fit(df[['c1_no_fold', 'c2_no_fold']])\n    \n    # Append the inertia to the list of inertias\n    inertias.append(model.inertia_)\n\nimport matplotlib.pyplot as plt\n\nplt.plot(ks, inertias, '-o', color='black')\nplt.xlabel('number of clusters, k')\nplt.ylabel('inertia')\nplt.xticks(ks)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_4_2_Crime_files/figure-html/cell-16-output-1.png){width=602 height=429}\n:::\n:::\n\n\nFour clusters looks good.\n\n## Visualising clusters\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nk_means_4 = KMeans(n_clusters = 3, init = 'random', n_init = 10)\nk_means_4.fit(df[['c1_no_fold', 'c2_no_fold']])\ndf['Four clusters'] = pd.Series(k_means_4.predict(df[['c1_no_fold', 'c2_no_fold']].values), index = df.index)\n```\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nsns.scatterplot(data = df, x = 'c1_no_fold', y = 'c2_no_fold', hue = 'Four clusters')\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n<Axes: xlabel='c1_no_fold', ylabel='c2_no_fold'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_4_2_Crime_files/figure-html/cell-18-output-2.png){width=587 height=429}\n:::\n:::\n\n\nHmm, might we interpret this plot? The plot is unclear. Let us assume c1 is an income component and c2 is an immigration component. Cluster 0 are places high on income and low on immigration. Cluster 2 are low on income and low on immigration. The interesting group are those high on immigration and relatively low on income.\n\nWe can include crime on the plot.\n\n::: {.cell .column-screen execution_count=18}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nplt.rcParams[\"figure.figsize\"] = (15,10)\nsns.scatterplot(data = df, x = 'c1_no_fold', y = 'c2_no_fold', hue = 'Four clusters', size = 'ViolentCrimesPerPop')\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\n<Axes: xlabel='c1_no_fold', ylabel='c2_no_fold'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_4_2_Crime_files/figure-html/cell-19-output-2.png){width=1183 height=799}\n:::\n:::\n\n\nAlas, we stop here in this exercise. You could work on this further. There are outliers you might want to remove. Or, at this stage, you might want to look at more components, 3 or 4 and look for some other factors.\n\n",
    "supporting": [
      "IM939_Lab_4_2_Crime_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}